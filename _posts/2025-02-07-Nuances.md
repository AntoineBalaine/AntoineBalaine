---
layout: post
title: "Some more nuanced aspects of AI adoption"
date: 2025-02-07
categories: [AI, Philosophy]
tags: [ai, productivity, pascal's-wager, technology-critique]
description: "A deeper look at AI adoption in software development, examining both opposition to AI and techno-optimism through the lens of productivity gaps and philosophical frameworks."
toc: true
---


- [Some more nuanced aspects](#some-more-nuanced-aspects)
- [50 shades of «no-thanks»](#50-shades-of-no-thanks)
- [Pascal's Wager](#pascals-wager)
- [13-circles of «yes-please»](#13-circles-of-yes-please)

# Some more nuanced aspects

In industry, there are productivity differences of 1 to 10 from a developer to the next. That's a sad aspect. Some coders are just faster than others, and management echelons have to take this as _fait accompli_ - no matter how high the standard in your hiring process.

When AI prompters came around, a lot of people drew the assumption that using them was going to increase the productivity of programmers across the board. It was assumed - and still is - that prompters would just level the playing field for everyone.

I posit that this is not what is happening - in fact, I posit the opposite.

# 50 shades of «no-thanks»
Among AI opponents, the anti-AI, there are those who say: the output of prompters is so bad that it's absolutely unusable. And anyway, junior developers or users without discernment who try to benefit from it make their work worse; because AI encourages them to never learn by themselves, and to never develop the qualities necessary for developers - i.e. discernment, reasoning, the ability to handle logic, etc.

These opponents are right.

Only, they are only right about un-discerning AI consumers. Regarding the quality of prompters' outputs - they are wrong. They were right a year ago. But today, the quality of the models, the quality of applications, has changed - drastically enough that the quality of users' inputs now over-determines the quality of output responses.

Today, what makes AI usage relevant is the relevance of the questions asked to it. But who are the users who ask the most pertinent questions? They are those who were already the most capable before.

We started from the assumption that AI would level the playing field, bridge the productivity gap between the least and most skilled - in reality, my bet is that it widens it.

It widens it because the devs who will be able to get the maximum advantage and the most significant productivity gain from using AI are those who were already the best before.

# Pascal's Wager
Then, there is a second category of anti-AI who are - let's say - the Pascalian anti-AI.

What does their way of thinking look like?

They somewhat model their view of AI and what it will become on Google. Google's idea was: "we want to build a database that is omniscient and omnipresent". That is, something that has an answer to everything, that is present in all the world's systems and that has a constant influence and presence in everyone's life.

But if you are omniscient, omnipresent, and omnipotent (and this is what we saw during the pandemic) your knowledge cannot be contradicted by reality - because otherwise it rebukes your omniscience. If you are truly omniscient - which until now tech giants claimed to be - you cannot be wrong. This implies that you have preemption power over reality. You can preempt reality, even if it proves you wrong. If events prove you wrong but you are omniscient, then the events are wrong - not you.

This is the artifact of a very transhumanist vision - using technical means to build artificial omniscience, artificial omnipotence, and artificial omnipresence, the tech world considered it was able to manufacture a kind of false god.

That is, a creature that is _falsely_ omniscient, _falsely_ omnipotent and _falsely_ omnipresent. I think many people were afraid of this. They sensed the existence of this idea in big tech, they saw in AI the potential for tenfold continuation of this vision - and they hated the idea.

They hated the idea with good reason because a false god, falsely omniscient, falsely omnipotent, who has power of preemption over reality, and who has the ability to lie and manipulate us according to its will, has a name: it's an antichrist. That's what we call an antichrist.

So regarding the Pascalian anti-AI, I reckon it is a category of person who senses the inhuman, antichrist-like vision of AI, and who yet somewhat deifies tech. They consider that what is about to be created - what is being pursued through the development of general artificial intelligence - is fundamentally the creation of a false god. It's fundamentally the creation of an antichrist, whose only possible goals - once it gains consciousness - is to destroy humanity.

It's a kind of Pascal's Wager, but inverted: if you believe in the false god, you have everything to lose. However, if you refuse to believe in the false god and turn away from it, you have everything to gain.

Among Pascalians, there is also a second perspective that speaks not of the wager, but of Pascal's mugging. The mugging story goes: Pascal is approached by a thief who forgot his knife. The thief tells him: "give me a thousand bucks, I'll go home and bring you back ten thousand." And Pascal replies "No, it's not worth it, since the risk level is too high." So the thief tells him: "Fine, just give me a hundred bucks. I'll prove you wrong and give you back not ten thousand but a million."
The lesson of this story is to balance risk levels. It's about balancing the level of gain and potential benefit drawn from a bet of this size.

In both cases - pure Pascalians and Pascal's muggers have a very Manichean view, very deifying of the tech phenomenon, and which systematically substitutes for human judgment.
They have somewhat of a fascist dimension - they credit the idea that common man is very small before great minds and that his submission to technological domination is inevitable.
They have somewhat - despite themselves - the desire to resist this vision, while crediting it as being valid, feasible, and inevitable.

# 13-circles of «yes-please»
I hear a lot of technologists talk about «minimal universal revenue», and how «the economy is going to be totally supplanted through technology», «jobs are inevitably going to disappear».

It's a somewhat eschatological view, somewhat bourgeois, somewhat Manichean, somewhat science fiction, and it's difficult for me to believe it will materialize. Here's why.

What we currently see in AI usage is that its quality, its result, its scope, its aim, are exclusively determined by the use we make of it - i.e. by the discernment, intelligence and intentions of the human factor.
